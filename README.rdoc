john cumbers articles with any matches:
['An experimental test of evolutionary trade-offs during temperature adaptation',
'CELL BIOLOGY: RNA Computing in a Living Cell',
'Coping with Our Cold Planet',
'GENE DUPLICATION UNDERLIES COLD ADAPTATION IN ANTARCTIC FISH',
'Look into the Seeds of Time',
'Measuring the activity of BioBrick promoters using an in vivo reference standard',
'PLANETARY SCIENCE: Asteroids Come of Age']

corresponding identifiers:
=> [[#<Identifier id: 509, article_id: 290, body: "URL:http://www.pnas.org/content/104/suppl.1/8649.ab...">],
    [#<Identifier id: 1072, article_id: 1013, body: "URL:http://www.sciencemag.org">],
    [#<Identifier id: 488, article_id: 264, body: "URL:http://aem.asm.org">],
    [#<Identifier id: 1174, article_id: 1136, body: "URL:http://jeb.biologists.org">],
    [#<Identifier id: 1019, article_id: 948, body: "URL:http://www.sciencemag.org">],
    [#<Identifier id: 1130, article_id: 1082, body: "URL:http://www.jbioleng.org/content/3/1/4">],
    [#<Identifier id: 1063, article_id: 1002, body: "URL:http://www.sciencemag.org">]]


======================


!!!!!
Dev notes: ~/log/2012-07-23-journal-club
!!!!!

# TODO: This PLoS URL doesn't resolve correctly:
# curl -d '{"url":"http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0040503","sessionid":"2"}' --header "Content-Type: application/json" localhost:1969/web
#
# TODO: This has no DOI, has citation_arxiv_id
# curl -d '{"url":"http://arxiv.org/abs/1206.6246","sessionid":"2"}' --header "Content-Type: application/json" localhost:1969/web
# curl -d '{"url":"http://www.cell.com/retrieve/pii/S0092867412008318","sessionid":"2"}' --header "Content-Type: application/json" localhost:1969/web
#
#
# Issue: this should use PubMed\ Central.js, but that translator isn't marked as "v" (server) compatible in the repo
# curl -d '{"url":"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2377243/","sessionid":"2"}' --header "Content-Type: application/json" localhost:1969/web

feedback:
  > john, mac, stuart
  _ oahack
  _ oahack member David Jay rails, social media analysis, UX Journal Lab (jay@thejournallab.com)
  _ joe pickrell
  _ william gunn

people:
  oahack@librelist.com / http://oahack.wikispaces.com/
  William Gunn, head of outreach at mendeley http://synthesis.williamgunn.org/about/
  Joe Pickrell http://www.genomesunzipped.org/2011/07/why-publish-science-in-peer-reviewed-journals.php#comments
  https://twitter.com/#!/jayunit/science
  Zotero plugin forum http://forums.zotero.org/categories/
  zotero-dev list
  mendeley-open-api list https://groups.google.com/forum/?fromgroups#!forum/mendeley-open-api-developers
  cameron neylon http://cameronneylon.net/category/blog/

articles:
  http://journal.webscience.org/308/2/websci10_submission_48.pdf
    Studying Scientific Discourse on the Web Using Bibliometrics: A Chemistry Blogging Case Study
  See papers on "Road map for altmetrics" http://altmetrics.org/manifesto/
  http://friendfeed.com/the-life-scientists

zotero-translator development
  https://github.com/zotero/translation-server/blob/7e21e119cf51241a97417aa8f94ec35721f10058/src/zotero.js#L51
  https://gist.github.com/3202704
  PMCjs failure, but no issue filed:
  http://zotero-translator-tests.s3-website-us-east-1.amazonaws.com/testTranslators.html#date=2012-07-29&browser=v&version=3.0.SOURCE.cb7640a
  fix sciencedirect.com identification? http://www.sciencedirect.com/science/article/pii/0019103579900940
  sciencemag full URLs:
    does not return DOI:
      http://www.sciencemag.org/content/329/5987/75.full
    returns DOI:
      http://www.sciencemag.org/content/329/5987/75


things I could do:
  x build discussion-query API
  x spike a zotero oauth frontend.
  x load researchblogging -- odd disconnect between citations - present in RB's html and atom, but is it always on the dest. page?
  x reddit archive loader http://reddit.com/r/[subreddit].[rss/json]?limit=[limit]&after=[after]
  x stop tracking ISSN
  x amend current user when oauthing to 2nd service
  x fetch discussion titles
  x Separate loading from identification: load with Page#identified_at nil.  Then, identify separately.  This will also be a good refactoring for IdentifyDiscussionJob, which shouldnt have to create the discussion.  Identification can spider at-will.
  x sketch designs for the frontend
  x spike a mendeley frontend.
  x import upon connect with nice screen
  _ run a nice initial import
    x r/science
    x nature news
    x reserachblogging
    x sciam
    x plos
    x discover
    : and identify pages
  x get it deployable.
    * heroku basic db is 10mil rows, $9/mo
  _ log all translationserver errors for categorization & improvement
    grep "could not load" log/development.log|wc -l
  x scrape discussion title
  x fix unicode char support in URI.parse
  _ cache name from zotero/mendeley/etc if available
  x frontend interface
    _ sketch tweaks to frontend discussion list including pagination
      _ implement
    _ sketch user flow to be prompted to add email to get notifications or to return
      _ implement
    x sketch landing page
      x implement
    x sketch user flow for connecting multiple accounts
      x implement
  _ use guest user until email is captured https://github.com/plataformatec/devise/wiki/How-To%3a-Create-a-guest-user
  ( Robust: )
  x present nice error if frontend can't contact engine
  _ hackernews archive loader [~] curl http://api.ihackernews.com/new/s4MVPmPI3d|jsonpp
  _ build rss/superfeedr loaders
  _ move identification to background worker
  x Once spidering, reject outgoing links at:
    * non-http/https protocols (javascript:, mailto:) same domain twitter.com facebook.com addthis.com youtube.com wikipedia.org qualtrics.com
  _ optimize, build bulk-identifier query API?
  x multiplex the identifier worker.  Not needed: already threaded.
  ( Nifty: )
  _ resolve discussion urls in Engine
    e.g.:
      Discussion on feedproxy.google.com
      http://feedproxy.google.com/~r/openhelix/GhpE/~3/sbJsnrXgW3A/
      Article: A Whole-Cell Computational Model Predicts Phenotype from Genotype
  _ see what else people use http://en.wikipedia.org/wiki/Comparison_of_reference_management_software
    _ import bibtex via https://rubygems.org/gems/bibtex-ruby ?
    _ spike a Papers-SDK frontend? http://www.mekentosj.com/developer
    _ http://www.colwiz.com/ ? ; bibtex http://www.colwiz.com/help#!library_export
    _ http://www.peaya.com/peayapaper/ ?
  _ scrape number of comments
  _ add an engine status page
  _ make use of reddit 'duplicates' http://www.reddit.com/r/science/duplicates/xx0xg/anthropologists_have_discovered_three_human/ for well-identified discussions?
  _ canonicalize URLs... but sometimes params are necessary (e.g. ?docid=123abc)
  _ boilerpipe to improve page spidering... but doesnt always work eg cuts off DOI at end of http://boilerpipe-web.appspot.com/extract?url=http%3A%2F%2Farstechnica.com%2Fscience%2F2012%2F08%2Fopen-air-quantum-teleportation-performed-across-a-97km-lake%2F&extractor=ArticleExtractor&output=htmlFragment
  _ improve xlation-server responses:
      Of 1991 pages fetched from r/science and researchblogging:
        * 24% identified,
        * 75% unidentifiable (http 501),
        * 0.9% errored (http 500),
        * 0.1% multiple results (http 300)
      _ handle HTTP 300 Multiple Choice responses from translation server
          # TODO: Handle HTTP 300 Multiple Choices:
          #
          # http://ehp03.niehs.nih.gov/article/info%3Adoi%2F10.1289%2Fehp.120-a305
          #
          # gives response from translation server
          #
          # zotero(5)(+0000001): HTTP/1.0 300 Multiple Choices
          # Content-Type: application/json
          # {"10.1289/ehp.120-a305":"Purifying Drinking Water with Sun, Salt, and Limes","10.2166/washdev.2012.043":"Optimizing the solar water disinfection (SODIS) method by decreasing turbidity with NaCl"}
      _ fixup some HTTP 501 Not Implemented responses from translation server (presumably from non-[server] translators)
          # TODO: Fixup 501 Method Not Implemented ones like
          # http://www.reddit.com/r/science/comments/xsmc0/alzheimers_protein_could_be_used_to_reverse_the/
          # which links to
          # http://www.sciencenews.org/view/generic/id/342721/title/Alzheimer%E2%80%99s_protein_could_help_in_MS
          # which is identifiable in browser, but not in server :(
          #
          # same for
          # http://arstechnica.com/science/2012/08/open-air-quantum-teleportation-performed-across-a-97km-lake/
          # discussed by http://www.reddit.com/r/science/comments/xxz59/openair_quantum_teleportation_has_been_performed/
          http://www.sciencemag.org/content/323/5917/1077

dont know what these were about:
  http://www.cell.com/current-biology/retrieve/pii/S0960982209006319
  http://www.cell.com/current-biology/retrieve/pii/S0960982206016368
  sources:
    http://scienceblogs.com/catdynamics/2012/07/26/lhc-higgs-mass-vs-susy/

names:
  pppreview.com
  paperquorum.com

Loaders
build more loaders... what do people use? sources feeds
  x http://www.nature.com/news/
      e.g. http://www.nature.com/news/cancer-stem-cells-tracked-1.11087
      refs:
        'ol.references li a' -- maybe only first 'a' in the 'li' ?
        'ul#article-refrences li a' (SIC)
        'ul#article-refrences li' -- older ones may be missing link href? EG:
          * http://www.nature.com/news/2009/090130/full/news.2009.71.html
            "Burt, R. K. et al. Lancet Neurol. Advanced online publication doi:10.1016/S1474-4422(09)70017-1 (2009)."
      RSS http://feeds.nature.com/NatureNewsComment
        * links directly 
  _ http://scienceblogging.org/
    it's a network - some member blogs are better than others:
      worthwhile:
        x sciam - content links, content textcites
          http://blogs.scientificamerican.com/home2.php?offset_n=30 (in steps of 30, up to 6900)
          "#singleBlogPost a"
        x discover - content links
        x plos - content links (described more below)
        _ guardian - content links, rare
        _ wired - content links
        _ cosmos - occasional linkcites
        _ http://www.scilogs.com/ - content links
        _ scilogs.eu - content links
      less good:
        nature network - now scilogs
        scienceblogs.com - rare, textcites
        scientopia - rare, textcites Z3988
        fieldofscience.com - rare, some links and some text, depends on the memberblog
        labspaces - occasional linkcites
        the gam
      unscored:
        freethought
        sci3.0
        sciblogsnz
        central
        aobblog
        occam
        scienceline
        nature education scitable
        allgeo
        smithsonian
        discovery
        natgeo
        agu
        nyt
        scimag
        quest
        npr-scifriday
        sci2.0
        psych-central
        psy-today
        quantum-diaries
        animal-planet
  _ via http://www.wired.com/wiredscience/2011/05/how-can-you-classify-science-bloggers/
    * http://twistedphysics.typepad.com/cocktail_party_physics/ linkcites
    * http://physicsbuzz.physicscentral.com/ linkcites
  _ science20
      http://www.science20.com/anthrophysis/unseen_coworkers_office_space_bacteria-92482
        links to http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0037849
  _ http://seqanswers.com
      Literature Watch forum: http://seqanswers.com/forums/forumdisplay.php?f=10&order=desc
      Other threads will "reference" paper(s) -- should this be displayed separately from a "discussion" in JC?
  _ http://www.nasw.org/taxonomy/term/99
      * National association of science writers, "science blogs" category
      * http://scienceofblogging.com/what-science-blog-networks-do-you-visit-an-update/


===================================================================================

heroku pg:info

heroku pg:credentials HEROKU_POSTGRESQL_IVORY

PGPASSWORD=somethingsomething /usr/local/bin/pg_restore --verbose --clean --no-acl --no-owner -h ec2-107-22-169-250.compute-1.amazonaws.com -U otznkieqwpadua -d db4pdiaj7fjhgs -p 5432 ./for_heroku2

===================================================================================
m1.small zotero-id3
  ssh -i ~/.aws/ec2key1.pem ubuntu@ec2-54-245-17-173.us-west-2.compute.amazonaws.com
t1.micro zotero-id4
  ssh -i ~/.aws/ec2key1.pem ubuntu@ec2-50-112-212-250.us-west-2.compute.amazonaws.com
--------------------------

Running the zotero/translation-server on ec2:

* Start with a lucid/ebc AMI: ami-fe5bd4ce
* Using lucid because some xulrunner-sdk prereqs are satisfied neatly by xulrunner-dev apt package, which isn't available in newer repo aka laziness.

  sudo apt-get update
  sudo apt-get install xulrunner-dev git-core

  mkdir dev ; cd dev

    wget http://ftp.mozilla.org/pub/mozilla.org/xulrunner/releases/14.0.1/sdk/xulrunner-14.0.1.en-US.linux-x86_64.sdk.tar.bz2
    tar xvf xulrunner-14.0.1.en-US.linux-x86_64.sdk.tar.bz2

    git clone https://github.com/zotero/translation-server.git
    cd translation-server

      ln -s ../xulrunner-sdk

      git submodule init
      git submodule update
      cd modules/zotero
        git submodule init
        git submodule update
        cd ../..

      echo "update config directory:"
      ls -d ~/dev/translation-server/modules/zotero/translators
      grep translation-server.translatorsDirectory config.js
      echo "use vim or nano or whatever, but you've gotta update it ^^"

      ./build.sh
      build/run_translation-server.sh

* Try a query!

  curl -d '{"url":"http://www.tandfonline.com/doi/abs/10.1080/15424060903167229","sessionid":"abc123"}' \
       --header "Content-Type: application/json" \
       localhost:1969/web

* Or:

  cd ~/dev/journalclub/engine

  ZOTERO_TRANSLATION_SERVER_URL=ec2-54-245-21-171.us-west-2.compute.amazonaws.com:1969 \
      rails runner "Page.unidentified.first.identify"
===================================================================================

ZOTERO_TRANSLATION_SERVER_URL=ec2-54-245-21-171.us-west-2.compute.amazonaws.com:1969 rails console
  ParallelIdentifier.new(Page.unidentified.order('id asc').where('id < 100000')).run
ZOTERO_TRANSLATION_SERVER_URL=ec2-50-112-212-250.us-west-2.compute.amazonaws.com:1969 rails console
  ParallelIdentifier.new(Page.unidentified.order('id asc').where('id > 100000')).run

  loop { Page.order('id asc').unidentified.first.identify rescue break }
  loop { Page.order('id asc').unidentified.last.identify rescue break }

class ParallelIdentifier
  def initialize(pages = Page.unidentified)
